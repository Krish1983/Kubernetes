apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 0a42e70657ab8be8b21bfd5e95a3091c737f2c1ea9a7e5d3d27e6df0d5ced007
      cni.projectcalico.org/podIP: 10.244.42.231/32
      cni.projectcalico.org/podIPs: 10.244.42.231/32
      tigera-operator.hash.operator.tigera.io/calico-apiserver-certs: c7b6ed2cab7b99882b4e7f931dfd81c8fae2280f
    creationTimestamp: "2024-07-26T16:55:00Z"
    generateName: calico-apiserver-7f5ddcdc69-
    labels:
      apiserver: "true"
      app.kubernetes.io/name: calico-apiserver
      k8s-app: calico-apiserver
      pod-template-hash: 7f5ddcdc69
    name: calico-apiserver-7f5ddcdc69-bh8xj
    namespace: calico-apiserver
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: calico-apiserver-7f5ddcdc69
      uid: 8fad5f60-e6c5-4676-bc76-e6cefd93f6cf
    resourceVersion: "51609"
    uid: e13db35b-21ab-451a-8214-38fde5085ef1
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                k8s-app: calico-apiserver
            namespaces:
            - calico-apiserver
            topologyKey: kubernetes.io/hostname
          weight: 100
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                k8s-app: calico-apiserver
            namespaces:
            - calico-apiserver
            topologyKey: topology.kubernetes.io/zone
          weight: 100
    containers:
    - args:
      - --secure-port=5443
      - --tls-private-key-file=/calico-apiserver-certs/tls.key
      - --tls-cert-file=/calico-apiserver-certs/tls.crt
      env:
      - name: DATASTORE_TYPE
        value: kubernetes
      - name: KUBERNETES_SERVICE_HOST
        value: 10.96.0.1
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      - name: MULTI_INTERFACE_MODE
        value: none
      image: docker.io/calico/apiserver:v3.28.0
      imagePullPolicy: IfNotPresent
      name: calico-apiserver
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: 5443
          scheme: HTTPS
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /calico-apiserver-certs
        name: calico-apiserver-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zdnx4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: control
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-apiserver
    serviceAccountName: calico-apiserver
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: calico-apiserver-certs
      secret:
        defaultMode: 420
        secretName: calico-apiserver-certs
    - name: kube-api-access-zdnx4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:55:01Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:22:04Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:22:04Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:55:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://fb801b57c722d14dc46e81a0a5be3391f237b077ffcfed3e77b3f931f3dd0c5e
      image: docker.io/calico/apiserver:v3.28.0
      imageID: docker.io/calico/apiserver@sha256:9a93592acff4fac0829f5254ee1335581a2cce16c4f11b36c4c89a48740d8efc
      lastState:
        terminated:
          containerID: containerd://1cdcfdce6195fa88c0baa374f32894835947fbdd0cb85056138c6307b56a6330
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:51Z"
      name: calico-apiserver
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:57Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 10.244.42.231
    podIPs:
    - ip: 10.244.42.231
    qosClass: BestEffort
    startTime: "2024-07-26T16:55:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: ced61d28b4528aba37c621d1956cdb3597dce7e71c32f839e74e3739711ea889
      cni.projectcalico.org/podIP: 10.244.42.226/32
      cni.projectcalico.org/podIPs: 10.244.42.226/32
      tigera-operator.hash.operator.tigera.io/calico-apiserver-certs: c7b6ed2cab7b99882b4e7f931dfd81c8fae2280f
    creationTimestamp: "2024-07-26T16:55:01Z"
    generateName: calico-apiserver-7f5ddcdc69-
    labels:
      apiserver: "true"
      app.kubernetes.io/name: calico-apiserver
      k8s-app: calico-apiserver
      pod-template-hash: 7f5ddcdc69
    name: calico-apiserver-7f5ddcdc69-v7vng
    namespace: calico-apiserver
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: calico-apiserver-7f5ddcdc69
      uid: 8fad5f60-e6c5-4676-bc76-e6cefd93f6cf
    resourceVersion: "51527"
    uid: 292944e0-50ef-40a9-9701-6b9d9dfbae49
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                k8s-app: calico-apiserver
            namespaces:
            - calico-apiserver
            topologyKey: kubernetes.io/hostname
          weight: 100
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                k8s-app: calico-apiserver
            namespaces:
            - calico-apiserver
            topologyKey: topology.kubernetes.io/zone
          weight: 100
    containers:
    - args:
      - --secure-port=5443
      - --tls-private-key-file=/calico-apiserver-certs/tls.key
      - --tls-cert-file=/calico-apiserver-certs/tls.crt
      env:
      - name: DATASTORE_TYPE
        value: kubernetes
      - name: KUBERNETES_SERVICE_HOST
        value: 10.96.0.1
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      - name: MULTI_INTERFACE_MODE
        value: none
      image: docker.io/calico/apiserver:v3.28.0
      imagePullPolicy: IfNotPresent
      name: calico-apiserver
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: 5443
          scheme: HTTPS
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /calico-apiserver-certs
        name: calico-apiserver-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-64wln
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: control
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-apiserver
    serviceAccountName: calico-apiserver
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: calico-apiserver-certs
      secret:
        defaultMode: 420
        secretName: calico-apiserver-certs
    - name: kube-api-access-64wln
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:55:01Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:48Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:48Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:55:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://84dc618a0fed0bc1477649591a7a2d09330355a707121f7f6abb9a21f8c9794b
      image: docker.io/calico/apiserver:v3.28.0
      imageID: docker.io/calico/apiserver@sha256:9a93592acff4fac0829f5254ee1335581a2cce16c4f11b36c4c89a48740d8efc
      lastState:
        terminated:
          containerID: containerd://9ab509b45e9a9e4a405248cc1809b7eb560c771ce66ee29305422e59ca1ad6fc
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:52Z"
      name: calico-apiserver
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:46Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 10.244.42.226
    podIPs:
    - ip: 10.244.42.226
    qosClass: BestEffort
    startTime: "2024-07-26T16:55:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 59d1206acdd977c8d7f6af2c9d2e49f54949f70160a65f04d9443ca93eaaa337
      cni.projectcalico.org/podIP: 10.244.42.227/32
      cni.projectcalico.org/podIPs: 10.244.42.227/32
      hash.operator.tigera.io/system: fdde45054a8ae4f629960ce37570929502e59449
      tigera-operator.hash.operator.tigera.io/tigera-ca-private: 179b5319dd81d22ffffc77a3bb37ee203a051c1f
    creationTimestamp: "2024-07-26T16:53:17Z"
    generateName: calico-kube-controllers-59488f4f55-
    labels:
      app.kubernetes.io/name: calico-kube-controllers
      k8s-app: calico-kube-controllers
      pod-template-hash: 59488f4f55
    name: calico-kube-controllers-59488f4f55-9qxk7
    namespace: calico-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: calico-kube-controllers-59488f4f55
      uid: 61bf0885-d5b1-42eb-91dd-33055d10c58e
    resourceVersion: "51521"
    uid: f74733f9-40cd-491a-a3e7-625324893ca4
  spec:
    containers:
    - env:
      - name: KUBE_CONTROLLERS_CONFIG_NAME
        value: default
      - name: DATASTORE_TYPE
        value: kubernetes
      - name: ENABLED_CONTROLLERS
        value: node
      - name: FIPS_MODE_ENABLED
        value: "false"
      - name: DISABLE_KUBE_CONTROLLERS_CONFIG_API
        value: "false"
      - name: KUBERNETES_SERVICE_HOST
        value: 10.96.0.1
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      - name: CA_CRT_PATH
        value: /etc/pki/tls/certs/tigera-ca-bundle.crt
      image: docker.io/calico/kube-controllers:v3.28.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - /usr/bin/check-status
          - -l
        failureThreshold: 6
        initialDelaySeconds: 10
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 10
      name: calico-kube-controllers
      readinessProbe:
        exec:
          command:
          - /usr/bin/check-status
          - -r
        failureThreshold: 3
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 10
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        runAsGroup: 0
        runAsNonRoot: true
        runAsUser: 999
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/pki/tls/certs
        name: tigera-ca-bundle
        readOnly: true
      - mountPath: /etc/pki/tls/cert.pem
        name: tigera-ca-bundle
        readOnly: true
        subPath: ca-bundle.crt
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bn44s
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: control
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-kube-controllers
    serviceAccountName: calico-kube-controllers
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: tigera-ca-bundle
      name: tigera-ca-bundle
    - name: kube-api-access-bn44s
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:54:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:47Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:47Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:54:10Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ad0519edfe1cbeb19f1fc931e597a128b19a220d91d893a34c0e019e8d89a944
      image: docker.io/calico/kube-controllers:v3.28.0
      imageID: docker.io/calico/kube-controllers@sha256:8f04e4772a2b3fa752bc7fb98cc89c7fa0ab88a341115ee8c5b6faa4180053fd
      lastState:
        terminated:
          containerID: containerd://cf754d74e198f2c6b96990efef712385b72c9e55cf03da214a6d254e98e54a27
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:51Z"
      name: calico-kube-controllers
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:46Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 10.244.42.227
    podIPs:
    - ip: 10.244.42.227
    qosClass: BestEffort
    startTime: "2024-07-26T16:54:10Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      hash.operator.tigera.io/cni-config: 0a4321e1231844b30534560ce90e56b5ba0a02a1
      hash.operator.tigera.io/system: fdde45054a8ae4f629960ce37570929502e59449
      tigera-operator.hash.operator.tigera.io/tigera-ca-private: 179b5319dd81d22ffffc77a3bb37ee203a051c1f
    creationTimestamp: "2024-07-26T16:53:17Z"
    generateName: calico-node-
    labels:
      app.kubernetes.io/name: calico-node
      controller-revision-hash: 96b6479b7
      k8s-app: calico-node
      pod-template-generation: "1"
    name: calico-node-s6ktv
    namespace: calico-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: calico-node
      uid: 0ed65a25-cfb1-41d6-b274-292bf1feccf5
    resourceVersion: "52083"
    uid: d51eb814-414c-4002-b82a-4c0c62cb0081
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - control
    containers:
    - env:
      - name: DATASTORE_TYPE
        value: kubernetes
      - name: WAIT_FOR_DATASTORE
        value: "true"
      - name: CLUSTER_TYPE
        value: k8s,operator,bgp
      - name: CALICO_DISABLE_FILE_LOGGING
        value: "false"
      - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
        value: ACCEPT
      - name: FELIX_HEALTHENABLED
        value: "true"
      - name: FELIX_HEALTHPORT
        value: "9099"
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: FELIX_TYPHAK8SNAMESPACE
        value: calico-system
      - name: FELIX_TYPHAK8SSERVICENAME
        value: calico-typha
      - name: FELIX_TYPHACAFILE
        value: /etc/pki/tls/certs/tigera-ca-bundle.crt
      - name: FELIX_TYPHACERTFILE
        value: /node-certs/tls.crt
      - name: FELIX_TYPHAKEYFILE
        value: /node-certs/tls.key
      - name: FIPS_MODE_ENABLED
        value: "false"
      - name: NO_DEFAULT_POOLS
        value: "true"
      - name: FELIX_TYPHACN
        value: typha-server
      - name: CALICO_MANAGE_CNI
        value: "true"
      - name: CALICO_NETWORKING_BACKEND
        value: bird
      - name: IP
        value: autodetect
      - name: IP_AUTODETECTION_METHOD
        value: first-found
      - name: IP6
        value: none
      - name: FELIX_IPV6SUPPORT
        value: "false"
      - name: KUBERNETES_SERVICE_HOST
        value: 10.96.0.1
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      image: docker.io/calico/node:v3.28.0
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/calico-node
            - -shutdown
      livenessProbe:
        failureThreshold: 3
        httpGet:
          host: localhost
          path: /liveness
          port: 9099
          scheme: HTTP
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 10
      name: calico-node
      readinessProbe:
        exec:
          command:
          - /bin/calico-node
          - -bird-ready
          - -felix-ready
        failureThreshold: 3
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 10
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
          - ALL
        privileged: true
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/pki/tls/certs
        name: tigera-ca-bundle
        readOnly: true
      - mountPath: /etc/pki/tls/cert.pem
        name: tigera-ca-bundle
        readOnly: true
        subPath: ca-bundle.crt
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/nodeagent
        name: policysync
      - mountPath: /node-certs
        name: node-certs
        readOnly: true
      - mountPath: /var/run/calico
        name: var-run-calico
      - mountPath: /var/lib/calico
        name: var-lib-calico
      - mountPath: /var/log/calico/cni
        name: cni-log-dir
      - mountPath: /host/etc/cni/net.d
        name: cni-net-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tnm8b
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - image: docker.io/calico/pod2daemon-flexvol:v3.28.0
      imagePullPolicy: IfNotPresent
      name: flexvol-driver
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
          - ALL
        privileged: true
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/driver
        name: flexvol-driver-host
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tnm8b
        readOnly: true
    - command:
      - /opt/cni/bin/install
      env:
      - name: CNI_CONF_NAME
        value: 10-calico.conflist
      - name: SLEEP
        value: "false"
      - name: CNI_NET_DIR
        value: /etc/cni/net.d
      - name: CNI_NETWORK_CONFIG
        valueFrom:
          configMapKeyRef:
            key: config
            name: cni-config
      - name: KUBERNETES_SERVICE_HOST
        value: 10.96.0.1
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      image: docker.io/calico/cni:v3.28.0
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
          - ALL
        privileged: true
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/opt/cni/bin
        name: cni-bin-dir
      - mountPath: /host/etc/cni/net.d
        name: cni-net-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tnm8b
        readOnly: true
    nodeName: control
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-node
    serviceAccountName: calico-node
    terminationGracePeriodSeconds: 5
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /var/run/nodeagent
        type: DirectoryOrCreate
      name: policysync
    - configMap:
        defaultMode: 420
        name: tigera-ca-bundle
      name: tigera-ca-bundle
    - name: node-certs
      secret:
        defaultMode: 420
        secretName: node-certs
    - hostPath:
        path: /var/run/calico
        type: ""
      name: var-run-calico
    - hostPath:
        path: /var/lib/calico
        type: ""
      name: var-lib-calico
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni-net-dir
    - hostPath:
        path: /var/log/calico/cni
        type: ""
      name: cni-log-dir
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
        type: DirectoryOrCreate
      name: flexvol-driver-host
    - name: kube-api-access-tnm8b
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:54:04Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:25:37Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:25:37Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:53:17Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://68d6ea2fc102b737fa63a1bc07144f603ddd5937d9c3481c47b581e63f8567f2
      image: docker.io/calico/node:v3.28.0
      imageID: docker.io/calico/node@sha256:385bf6391fea031649b8575799248762a2caece86e6e3f33ffee19c0c096e6a8
      lastState:
        terminated:
          containerID: containerd://00318de760cf86018ac1b11ea76c6ab9f413539f2d72a4efcbcbd67af9be9e96
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:37Z"
      name: calico-node
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:16Z"
    hostIP: 192.168.1.2
    initContainerStatuses:
    - containerID: containerd://3a101cf3495b136a934fdf7bb63cff9689d6cb8e751e9038c0dbd391d96fce6f
      image: docker.io/calico/pod2daemon-flexvol:v3.28.0
      imageID: docker.io/calico/pod2daemon-flexvol@sha256:2054fc9485e11bdde7ec8e22bca88bbf3a0f777f6c17509045a427294aa0a54b
      lastState: {}
      name: flexvol-driver
      ready: true
      restartCount: 5
      started: false
      state:
        terminated:
          containerID: containerd://3a101cf3495b136a934fdf7bb63cff9689d6cb8e751e9038c0dbd391d96fce6f
          exitCode: 0
          finishedAt: "2024-08-04T11:21:10Z"
          reason: Completed
          startedAt: "2024-08-04T11:21:09Z"
    - containerID: containerd://71a84456d19b735abd82d6bb2ad6761b3498516c1f89d316b26018f6914844f7
      image: docker.io/calico/cni:v3.28.0
      imageID: docker.io/calico/cni@sha256:cef0c907b8f4cadc63701d371e6f24d325795bcf0be84d6a517e33000ff35f70
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://71a84456d19b735abd82d6bb2ad6761b3498516c1f89d316b26018f6914844f7
          exitCode: 0
          finishedAt: "2024-08-04T11:21:15Z"
          reason: Completed
          startedAt: "2024-08-04T11:21:13Z"
    phase: Running
    podIP: 192.168.1.2
    podIPs:
    - ip: 192.168.1.2
    qosClass: BestEffort
    startTime: "2024-07-26T16:53:17Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      hash.operator.tigera.io/cni-config: 0a4321e1231844b30534560ce90e56b5ba0a02a1
      hash.operator.tigera.io/system: fdde45054a8ae4f629960ce37570929502e59449
      tigera-operator.hash.operator.tigera.io/tigera-ca-private: 179b5319dd81d22ffffc77a3bb37ee203a051c1f
    creationTimestamp: "2024-07-26T16:55:36Z"
    generateName: calico-node-
    labels:
      app.kubernetes.io/name: calico-node
      controller-revision-hash: 96b6479b7
      k8s-app: calico-node
      pod-template-generation: "1"
    name: calico-node-tft54
    namespace: calico-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: calico-node
      uid: 0ed65a25-cfb1-41d6-b274-292bf1feccf5
    resourceVersion: "52123"
    uid: 5c465635-8f4c-4d80-b655-fde787362cdc
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - node1
    containers:
    - env:
      - name: DATASTORE_TYPE
        value: kubernetes
      - name: WAIT_FOR_DATASTORE
        value: "true"
      - name: CLUSTER_TYPE
        value: k8s,operator,bgp
      - name: CALICO_DISABLE_FILE_LOGGING
        value: "false"
      - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
        value: ACCEPT
      - name: FELIX_HEALTHENABLED
        value: "true"
      - name: FELIX_HEALTHPORT
        value: "9099"
      - name: NODENAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: FELIX_TYPHAK8SNAMESPACE
        value: calico-system
      - name: FELIX_TYPHAK8SSERVICENAME
        value: calico-typha
      - name: FELIX_TYPHACAFILE
        value: /etc/pki/tls/certs/tigera-ca-bundle.crt
      - name: FELIX_TYPHACERTFILE
        value: /node-certs/tls.crt
      - name: FELIX_TYPHAKEYFILE
        value: /node-certs/tls.key
      - name: FIPS_MODE_ENABLED
        value: "false"
      - name: NO_DEFAULT_POOLS
        value: "true"
      - name: FELIX_TYPHACN
        value: typha-server
      - name: CALICO_MANAGE_CNI
        value: "true"
      - name: CALICO_NETWORKING_BACKEND
        value: bird
      - name: IP
        value: autodetect
      - name: IP_AUTODETECTION_METHOD
        value: first-found
      - name: IP6
        value: none
      - name: FELIX_IPV6SUPPORT
        value: "false"
      - name: KUBERNETES_SERVICE_HOST
        value: 10.96.0.1
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      image: docker.io/calico/node:v3.28.0
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/calico-node
            - -shutdown
      livenessProbe:
        failureThreshold: 3
        httpGet:
          host: localhost
          path: /liveness
          port: 9099
          scheme: HTTP
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 10
      name: calico-node
      readinessProbe:
        exec:
          command:
          - /bin/calico-node
          - -bird-ready
          - -felix-ready
        failureThreshold: 3
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 10
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
          - ALL
        privileged: true
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/pki/tls/certs
        name: tigera-ca-bundle
        readOnly: true
      - mountPath: /etc/pki/tls/cert.pem
        name: tigera-ca-bundle
        readOnly: true
        subPath: ca-bundle.crt
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /var/run/nodeagent
        name: policysync
      - mountPath: /node-certs
        name: node-certs
        readOnly: true
      - mountPath: /var/run/calico
        name: var-run-calico
      - mountPath: /var/lib/calico
        name: var-lib-calico
      - mountPath: /var/log/calico/cni
        name: cni-log-dir
      - mountPath: /host/etc/cni/net.d
        name: cni-net-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fqvb5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    initContainers:
    - image: docker.io/calico/pod2daemon-flexvol:v3.28.0
      imagePullPolicy: IfNotPresent
      name: flexvol-driver
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
          - ALL
        privileged: true
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/driver
        name: flexvol-driver-host
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fqvb5
        readOnly: true
    - command:
      - /opt/cni/bin/install
      env:
      - name: CNI_CONF_NAME
        value: 10-calico.conflist
      - name: SLEEP
        value: "false"
      - name: CNI_NET_DIR
        value: /etc/cni/net.d
      - name: CNI_NETWORK_CONFIG
        valueFrom:
          configMapKeyRef:
            key: config
            name: cni-config
      - name: KUBERNETES_SERVICE_HOST
        value: 10.96.0.1
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      image: docker.io/calico/cni:v3.28.0
      imagePullPolicy: IfNotPresent
      name: install-cni
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
          - ALL
        privileged: true
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/opt/cni/bin
        name: cni-bin-dir
      - mountPath: /host/etc/cni/net.d
        name: cni-net-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fqvb5
        readOnly: true
    nodeName: node1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-node
    serviceAccountName: calico-node
    terminationGracePeriodSeconds: 5
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /var/run/nodeagent
        type: DirectoryOrCreate
      name: policysync
    - configMap:
        defaultMode: 420
        name: tigera-ca-bundle
      name: tigera-ca-bundle
    - name: node-certs
      secret:
        defaultMode: 420
        secretName: node-certs
    - hostPath:
        path: /var/run/calico
        type: ""
      name: var-run-calico
    - hostPath:
        path: /var/lib/calico
        type: ""
      name: var-lib-calico
    - hostPath:
        path: /opt/cni/bin
        type: ""
      name: cni-bin-dir
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni-net-dir
    - hostPath:
        path: /var/log/calico/cni
        type: ""
      name: cni-log-dir
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
        type: DirectoryOrCreate
      name: flexvol-driver-host
    - name: kube-api-access-fqvb5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T17:42:02Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:25:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:25:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:55:36Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f263d93477e1f8446af1254b7d16443f504ae37c1a662d38511f26e2a17c1052
      image: docker.io/calico/node:v3.28.0
      imageID: docker.io/calico/node@sha256:385bf6391fea031649b8575799248762a2caece86e6e3f33ffee19c0c096e6a8
      lastState:
        terminated:
          containerID: containerd://edea41a6fb3a714c5e94e2d0d7478debead081dd3e13e7ede60d789c27218f8c
          exitCode: 255
          finishedAt: "2024-08-04T11:25:12Z"
          reason: Unknown
          startedAt: "2024-08-04T08:59:11Z"
      name: calico-node
      ready: true
      restartCount: 4
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:25:28Z"
    hostIP: 192.168.1.3
    initContainerStatuses:
    - containerID: containerd://6abae2d5ad905b5a6525750c67eab9492f31804e7eb526eecb5ce541631c59ea
      image: docker.io/calico/pod2daemon-flexvol:v3.28.0
      imageID: docker.io/calico/pod2daemon-flexvol@sha256:2054fc9485e11bdde7ec8e22bca88bbf3a0f777f6c17509045a427294aa0a54b
      lastState: {}
      name: flexvol-driver
      ready: true
      restartCount: 4
      started: false
      state:
        terminated:
          containerID: containerd://6abae2d5ad905b5a6525750c67eab9492f31804e7eb526eecb5ce541631c59ea
          exitCode: 0
          finishedAt: "2024-08-04T11:25:25Z"
          reason: Completed
          startedAt: "2024-08-04T11:25:24Z"
    - containerID: containerd://c60e00e44046a8f22a7f66e80fa80a893d59ef16d4e5dcad54d84d5e05edcbc9
      image: docker.io/calico/cni:v3.28.0
      imageID: docker.io/calico/cni@sha256:cef0c907b8f4cadc63701d371e6f24d325795bcf0be84d6a517e33000ff35f70
      lastState: {}
      name: install-cni
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://c60e00e44046a8f22a7f66e80fa80a893d59ef16d4e5dcad54d84d5e05edcbc9
          exitCode: 0
          finishedAt: "2024-08-04T11:25:27Z"
          reason: Completed
          startedAt: "2024-08-04T11:25:25Z"
    phase: Running
    podIP: 192.168.1.3
    podIPs:
    - ip: 192.168.1.3
    qosClass: BestEffort
    startTime: "2024-07-26T17:40:54Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      hash.operator.tigera.io/system: fdde45054a8ae4f629960ce37570929502e59449
      tigera-operator.hash.operator.tigera.io/tigera-ca-private: 179b5319dd81d22ffffc77a3bb37ee203a051c1f
      tigera-operator.hash.operator.tigera.io/typha-certs: 8a8f7419ba03005d96764f9b47e43f85815e7fbc
    creationTimestamp: "2024-07-26T16:53:17Z"
    generateName: calico-typha-776b6c4d8d-
    labels:
      app.kubernetes.io/name: calico-typha
      k8s-app: calico-typha
      pod-template-hash: 776b6c4d8d
    name: calico-typha-776b6c4d8d-sndhg
    namespace: calico-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: calico-typha-776b6c4d8d
      uid: 6071492b-e799-4636-9c31-554138947d66
    resourceVersion: "51625"
    uid: f3f1ef0d-f4b6-41cd-bfa5-69ab3f390973
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - calico-typha
            topologyKey: topology.kubernetes.io/zone
          weight: 1
    containers:
    - env:
      - name: TYPHA_LOGSEVERITYSCREEN
        value: info
      - name: TYPHA_LOGFILEPATH
        value: none
      - name: TYPHA_LOGSEVERITYSYS
        value: none
      - name: TYPHA_CONNECTIONREBALANCINGMODE
        value: kubernetes
      - name: TYPHA_DATASTORETYPE
        value: kubernetes
      - name: TYPHA_HEALTHENABLED
        value: "true"
      - name: TYPHA_HEALTHPORT
        value: "9098"
      - name: TYPHA_K8SNAMESPACE
        value: calico-system
      - name: TYPHA_CAFILE
        value: /etc/pki/tls/certs/tigera-ca-bundle.crt
      - name: TYPHA_SERVERCERTFILE
        value: /typha-certs/tls.crt
      - name: TYPHA_SERVERKEYFILE
        value: /typha-certs/tls.key
      - name: TYPHA_FIPSMODEENABLED
        value: "false"
      - name: TYPHA_SHUTDOWNTIMEOUTSECS
        value: "300"
      - name: TYPHA_CLIENTCN
        value: typha-client
      - name: KUBERNETES_SERVICE_HOST
        value: 10.96.0.1
      - name: KUBERNETES_SERVICE_PORT
        value: "443"
      image: docker.io/calico/typha:v3.28.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          host: localhost
          path: /liveness
          port: 9098
          scheme: HTTP
        periodSeconds: 60
        successThreshold: 1
        timeoutSeconds: 10
      name: calico-typha
      ports:
      - containerPort: 5473
        hostPort: 5473
        name: calico-typha
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: localhost
          path: /readiness
          port: 9098
          scheme: HTTP
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 10
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        privileged: false
        runAsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/pki/tls/certs
        name: tigera-ca-bundle
        readOnly: true
      - mountPath: /etc/pki/tls/cert.pem
        name: tigera-ca-bundle
        readOnly: true
        subPath: ca-bundle.crt
      - mountPath: /typha-certs
        name: typha-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7drkj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: control
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: calico-typha
    serviceAccountName: calico-typha
    terminationGracePeriodSeconds: 300
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: tigera-ca-bundle
      name: tigera-ca-bundle
    - name: typha-certs
      secret:
        defaultMode: 420
        secretName: typha-certs
    - name: kube-api-access-7drkj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:53:17Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:22:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:22:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:53:17Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://8899579873dcecf0784b3a33e081b25b97ca2a9cc2408090746c066e22caad18
      image: docker.io/calico/typha:v3.28.0
      imageID: docker.io/calico/typha@sha256:77677c3b2614923988960151008ffc876582c722199e4b0a9a084a70b6539637
      lastState:
        terminated:
          containerID: containerd://5885523bd888356dbcc983c97441e81b677d841e4269bf0a33e95e33dcf1245e
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:33Z"
      name: calico-typha
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:10Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 192.168.1.2
    podIPs:
    - ip: 192.168.1.2
    qosClass: BestEffort
    startTime: "2024-07-26T16:53:17Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 77b8737c06eb71b95791148026ab9338186783b75b5651636e0deabe47b623c5
      cni.projectcalico.org/podIP: 10.244.166.135/32
      cni.projectcalico.org/podIPs: 10.244.166.135/32
    creationTimestamp: "2024-07-26T16:55:36Z"
    generateName: csi-node-driver-
    labels:
      app.kubernetes.io/name: csi-node-driver
      controller-revision-hash: 7b77ff9f6c
      k8s-app: csi-node-driver
      name: csi-node-driver
      pod-template-generation: "1"
    name: csi-node-driver-8msk9
    namespace: calico-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: csi-node-driver
      uid: be9fa4a5-2644-4596-b3bf-7c8c3c5f4904
    resourceVersion: "52121"
    uid: eaca3baf-ee48-4e56-80e0-44595ce137c1
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - node1
    containers:
    - args:
      - --nodeid=$(KUBE_NODE_NAME)
      - --loglevel=$(LOG_LEVEL)
      env:
      - name: LOG_LEVEL
        value: warn
      - name: KUBE_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: docker.io/calico/csi:v3.28.0
      imagePullPolicy: IfNotPresent
      name: calico-csi
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
          - ALL
        privileged: true
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run
        name: varrun
      - mountPath: /csi
        name: socket-dir
      - mountPath: /var/lib/kubelet
        mountPropagation: Bidirectional
        name: kubelet-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bsrk4
        readOnly: true
    - args:
      - --v=5
      - --csi-address=$(ADDRESS)
      - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)
      env:
      - name: ADDRESS
        value: /csi/csi.sock
      - name: DRIVER_REG_SOCK_PATH
        value: /var/lib/kubelet/plugins/csi.tigera.io/csi.sock
      - name: KUBE_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: docker.io/calico/node-driver-registrar:v3.28.0
      imagePullPolicy: IfNotPresent
      name: csi-node-driver-registrar
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
          - ALL
        privileged: true
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /csi
        name: socket-dir
      - mountPath: /registration
        name: registration-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bsrk4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: node1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run
        type: ""
      name: varrun
    - hostPath:
        path: /var/lib/kubelet
        type: Directory
      name: kubelet-dir
    - hostPath:
        path: /var/lib/kubelet/plugins/csi.tigera.io
        type: DirectoryOrCreate
      name: socket-dir
    - hostPath:
        path: /var/lib/kubelet/plugins_registry
        type: Directory
      name: registration-dir
    - name: kube-api-access-bsrk4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T17:40:54Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:25:45Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:25:45Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:55:36Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://90858513a5a481aa2fc9d8bbf095c23dc0c6e49eff814c598059a85a8de6c09d
      image: docker.io/calico/csi:v3.28.0
      imageID: docker.io/calico/csi@sha256:6590b3466d5bfeb26e0337b85bdd25ff5361e6373e5e5a72fab5212a65c62247
      lastState:
        terminated:
          containerID: containerd://51c003bd29ae7e920ab684e47f98a7a10a5226f5e112024bd82f0032684af554
          exitCode: 255
          finishedAt: "2024-08-04T11:25:12Z"
          reason: Unknown
          startedAt: "2024-08-04T08:59:21Z"
      name: calico-csi
      ready: true
      restartCount: 4
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:25:45Z"
    - containerID: containerd://3b0a596ed897ce45353d8d3b37fddcd6fabc7cb2371c99d662e8d706f4da181a
      image: docker.io/calico/node-driver-registrar:v3.28.0
      imageID: docker.io/calico/node-driver-registrar@sha256:25a00aca99eb67ca8fc6fda2888bdce0f8bb6704d71433f3daba52e72061a785
      lastState:
        terminated:
          containerID: containerd://4872b68390debdb3f60d25d35f5e473e513de96cd8bb5ffd5d3e355cef791969
          exitCode: 255
          finishedAt: "2024-08-04T11:25:12Z"
          reason: Unknown
          startedAt: "2024-08-04T08:59:21Z"
      name: csi-node-driver-registrar
      ready: true
      restartCount: 4
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:25:45Z"
    hostIP: 192.168.1.3
    phase: Running
    podIP: 10.244.166.135
    podIPs:
    - ip: 10.244.166.135
    qosClass: BestEffort
    startTime: "2024-07-26T17:40:54Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 516c9d5a36172a3462b3671d15948429d0926aace23a355aa0f984525ff86bd4
      cni.projectcalico.org/podIP: 10.244.42.230/32
      cni.projectcalico.org/podIPs: 10.244.42.230/32
    creationTimestamp: "2024-07-26T16:53:17Z"
    generateName: csi-node-driver-
    labels:
      app.kubernetes.io/name: csi-node-driver
      controller-revision-hash: 7b77ff9f6c
      k8s-app: csi-node-driver
      name: csi-node-driver
      pod-template-generation: "1"
    name: csi-node-driver-fkmr9
    namespace: calico-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: csi-node-driver
      uid: be9fa4a5-2644-4596-b3bf-7c8c3c5f4904
    resourceVersion: "51583"
    uid: f50d519c-e0dc-4bda-89b4-15c3d90856d9
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - control
    containers:
    - args:
      - --nodeid=$(KUBE_NODE_NAME)
      - --loglevel=$(LOG_LEVEL)
      env:
      - name: LOG_LEVEL
        value: warn
      - name: KUBE_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: docker.io/calico/csi:v3.28.0
      imagePullPolicy: IfNotPresent
      name: calico-csi
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
          - ALL
        privileged: true
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run
        name: varrun
      - mountPath: /csi
        name: socket-dir
      - mountPath: /var/lib/kubelet
        mountPropagation: Bidirectional
        name: kubelet-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6tfxd
        readOnly: true
    - args:
      - --v=5
      - --csi-address=$(ADDRESS)
      - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)
      env:
      - name: ADDRESS
        value: /csi/csi.sock
      - name: DRIVER_REG_SOCK_PATH
        value: /var/lib/kubelet/plugins/csi.tigera.io/csi.sock
      - name: KUBE_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: docker.io/calico/node-driver-registrar:v3.28.0
      imagePullPolicy: IfNotPresent
      name: csi-node-driver-registrar
      resources: {}
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
          - ALL
        privileged: true
        runAsGroup: 0
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /csi
        name: socket-dir
      - mountPath: /registration
        name: registration-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6tfxd
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: control
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - hostPath:
        path: /var/run
        type: ""
      name: varrun
    - hostPath:
        path: /var/lib/kubelet
        type: Directory
      name: kubelet-dir
    - hostPath:
        path: /var/lib/kubelet/plugins/csi.tigera.io
        type: DirectoryOrCreate
      name: socket-dir
    - hostPath:
        path: /var/lib/kubelet/plugins_registry
        type: Directory
      name: registration-dir
    - name: kube-api-access-6tfxd
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:53:17Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:57Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:57Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:53:17Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://d60652fb47416d245dfec8b344158d244a5895742db91e67044802f131b31ea7
      image: docker.io/calico/csi:v3.28.0
      imageID: docker.io/calico/csi@sha256:6590b3466d5bfeb26e0337b85bdd25ff5361e6373e5e5a72fab5212a65c62247
      lastState:
        terminated:
          containerID: containerd://c6113c0499073110e51d71fca2dca2a515094a68fc03407c62e4f5198198bfee
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:48Z"
      name: calico-csi
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:56Z"
    - containerID: containerd://834c4c7ee246b73c06173f6ce0bb01cd23618044578695ad037470d3c4f93f28
      image: docker.io/calico/node-driver-registrar:v3.28.0
      imageID: docker.io/calico/node-driver-registrar@sha256:25a00aca99eb67ca8fc6fda2888bdce0f8bb6704d71433f3daba52e72061a785
      lastState:
        terminated:
          containerID: containerd://0c9172ba1b82dcb76765d86ea899b306cb8fc6371553f3567f43f8ad0084f3e5
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:48Z"
      name: csi-node-driver-registrar
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:57Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 10.244.42.230
    podIPs:
    - ip: 10.244.42.230
    qosClass: BestEffort
    startTime: "2024-07-26T16:53:17Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 59e2fce3a0bb5939cbaba06c71aed07819dceed5807fc2bfc3c8095cb4dd1ad5
      cni.projectcalico.org/podIP: 10.244.42.229/32
      cni.projectcalico.org/podIPs: 10.244.42.229/32
    creationTimestamp: "2024-08-04T06:14:43Z"
    generateName: nginx-deployment-54586f94c-
    labels:
      app: temp-nginx
      pod-template-hash: 54586f94c
    name: nginx-deployment-54586f94c-mbnz2
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nginx-deployment-54586f94c
      uid: 2d26a8d9-01c3-4755-8167-414d28b87857
    resourceVersion: "51565"
    uid: feb90269-00d3-4f7f-acfd-68bbbbe16e75
  spec:
    containers:
    - image: nginx:1.14.2
      imagePullPolicy: IfNotPresent
      name: nginx
      ports:
      - containerPort: 80
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-tp98j
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: control
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-tp98j
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T06:14:43Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:56Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:56Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T06:14:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ec0acf29306b4f3c190e2f4322fdc911e8e79ad3d4b52233e570b18a20af902a
      image: docker.io/library/nginx:1.14.2
      imageID: docker.io/library/nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df7563c3a2a6abe24160306b8d
      lastState:
        terminated:
          containerID: containerd://919ca3fc510af05dbba38a83324ebfec0b3478021e051a185db3063083eead25
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:47Z"
      name: nginx
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:55Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 10.244.42.229
    podIPs:
    - ip: 10.244.42.229
    qosClass: BestEffort
    startTime: "2024-08-04T06:14:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 28985ecaee80dfa0ef0dec85d35d9eadae8fc564557166a9d924ad0bc0edecfd
      cni.projectcalico.org/podIP: 10.244.42.228/32
      cni.projectcalico.org/podIPs: 10.244.42.228/32
    creationTimestamp: "2024-07-26T16:10:19Z"
    generateName: coredns-5dd5756b68-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 5dd5756b68
    name: coredns-5dd5756b68-hvncl
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-5dd5756b68
      uid: 60a41ec5-76d4-462f-a9a8-ae1ef9ebba00
    resourceVersion: "51509"
    uid: 37c532db-bcf4-4873-8eae-bb98334d673c
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.10.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jr2bh
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: control
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-jr2bh
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:54:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:46Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:46Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:54:10Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c6a3d57850d2d8e4bf3236c52b8bc5ba6d55fa82358c7718ee11be6b382afe64
      image: registry.k8s.io/coredns/coredns:v1.10.1
      imageID: registry.k8s.io/coredns/coredns@sha256:a0ead06651cf580044aeb0a0feba63591858fb2e43ade8c9dea45a6a89ae7e5e
      lastState:
        terminated:
          containerID: containerd://d2ebbb2ebafb67be1b395e28779848760a1ef293c1df468e16c66af9ae4f9a1e
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:37Z"
      name: coredns
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:46Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 10.244.42.228
    podIPs:
    - ip: 10.244.42.228
    qosClass: Burstable
    startTime: "2024-07-26T16:54:10Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: 69d664d2e0bee0ac5fca8a7414d0c481e24b6e97bca6940333893a8bd0d50023
      cni.projectcalico.org/podIP: 10.244.42.225/32
      cni.projectcalico.org/podIPs: 10.244.42.225/32
    creationTimestamp: "2024-07-26T16:10:19Z"
    generateName: coredns-5dd5756b68-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 5dd5756b68
    name: coredns-5dd5756b68-vlvnp
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-5dd5756b68
      uid: 60a41ec5-76d4-462f-a9a8-ae1ef9ebba00
    resourceVersion: "51513"
    uid: 773f560f-c5e4-42d0-bb19-0af72cbc8d88
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.10.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-p86rj
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: control
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-p86rj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:54:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:46Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:46Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:54:10Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://5aa4c3008dcde637ebb0ccf63ee7203204a71a0f24de368786d5b3ad5b759ae5
      image: registry.k8s.io/coredns/coredns:v1.10.1
      imageID: registry.k8s.io/coredns/coredns@sha256:a0ead06651cf580044aeb0a0feba63591858fb2e43ade8c9dea45a6a89ae7e5e
      lastState:
        terminated:
          containerID: containerd://2c45d2e514ec0c8ed1f9fde4e12743d3c2bbbad1f2149741916abd727028e061
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:37Z"
      name: coredns
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:45Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 10.244.42.225
    podIPs:
    - ip: 10.244.42.225
    qosClass: Burstable
    startTime: "2024-07-26T16:54:10Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/etcd.advertise-client-urls: https://192.168.1.2:2379
      kubernetes.io/config.hash: b3033bbcee45c07c7236e51e6fe76d9d
      kubernetes.io/config.mirror: b3033bbcee45c07c7236e51e6fe76d9d
      kubernetes.io/config.seen: "2024-07-26T16:09:56.162697716Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-07-26T16:10:06Z"
    labels:
      component: etcd
      tier: control-plane
    name: etcd-control
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: control
      uid: 911a21c3-1fff-41f1-82b9-2396928106e8
    resourceVersion: "51383"
    uid: 7e4636f2-63fe-404f-81fa-78d69f079bd1
  spec:
    containers:
    - command:
      - etcd
      - --advertise-client-urls=https://192.168.1.2:2379
      - --cert-file=/etc/kubernetes/pki/etcd/server.crt
      - --client-cert-auth=true
      - --data-dir=/var/lib/etcd
      - --experimental-initial-corrupt-check=true
      - --experimental-watch-progress-notify-interval=5s
      - --initial-advertise-peer-urls=https://192.168.1.2:2380
      - --initial-cluster=control=https://192.168.1.2:2380
      - --key-file=/etc/kubernetes/pki/etcd/server.key
      - --listen-client-urls=https://127.0.0.1:2379,https://192.168.1.2:2379
      - --listen-metrics-urls=http://127.0.0.1:2381
      - --listen-peer-urls=https://192.168.1.2:2380
      - --name=control
      - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
      - --peer-client-cert-auth=true
      - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
      - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      - --snapshot-count=10000
      - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      image: registry.k8s.io/etcd:3.5.12-0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health?exclude=NOSPACE&serializable=true
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /health?serializable=false
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/etcd
        name: etcd-data
      - mountPath: /etc/kubernetes/pki/etcd
        name: etcd-certs
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: control
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki/etcd
        type: DirectoryOrCreate
      name: etcd-certs
    - hostPath:
        path: /var/lib/etcd
        type: DirectoryOrCreate
      name: etcd-data
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:01Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:15Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:15Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4ab3806625a32b7fd37a807ac8cdc693aa489dc58592e3e50cfa996c7c3c13ca
      image: registry.k8s.io/etcd:3.5.12-0
      imageID: registry.k8s.io/etcd@sha256:44a8e24dcbba3470ee1fee21d5e88d128c936e9b55d4bc51fbef8086f8ed123b
      lastState:
        terminated:
          containerID: containerd://1b37f6cd61583e09de8c9dfcb43733870ca14e91e78cdea2c84a5f44fb9dcbfe
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:27Z"
      name: etcd
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:03Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 192.168.1.2
    podIPs:
    - ip: 192.168.1.2
    qosClass: Burstable
    startTime: "2024-08-04T11:21:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 192.168.1.2:6443
      kubernetes.io/config.hash: a89cc7f56674e39d90fd415c5dee1330
      kubernetes.io/config.mirror: a89cc7f56674e39d90fd415c5dee1330
      kubernetes.io/config.seen: "2024-07-26T16:10:07.368114548Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-07-26T16:10:07Z"
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-control
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: control
      uid: 911a21c3-1fff-41f1-82b9-2396928106e8
    resourceVersion: "51392"
    uid: e3940a90-5439-476c-abd4-fb446628a3c8
  spec:
    containers:
    - command:
      - kube-apiserver
      - --advertise-address=192.168.1.2
      - --allow-privileged=true
      - --authorization-mode=Node,RBAC
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --enable-admission-plugins=NodeRestriction
      - --enable-bootstrap-token-auth=true
      - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
      - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
      - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
      - --etcd-servers=https://127.0.0.1:2379
      - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      - --requestheader-allowed-names=front-proxy-client
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --secure-port=6443
      - --service-account-issuer=https://kubernetes.default.svc.cluster.local
      - --service-account-key-file=/etc/kubernetes/pki/sa.pub
      - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      image: registry.k8s.io/kube-apiserver:v1.28.12
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 192.168.1.2
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: 192.168.1.2
          path: /readyz
          port: 6443
          scheme: HTTPS
        periodSeconds: 1
        successThreshold: 1
        timeoutSeconds: 15
      resources:
        requests:
          cpu: 250m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 192.168.1.2
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/pki
        name: etc-pki
        readOnly: true
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: control
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: etc-pki
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:01Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://c10687840e8115219df0478addde5f46af8ff763905ea181bee4ddc6d5de32cd
      image: registry.k8s.io/kube-apiserver:v1.28.12
      imageID: registry.k8s.io/kube-apiserver@sha256:ac3b6876d95fe7b7691e69f2161a5466adbe9d72d44f342d595674321ce16d23
      lastState:
        terminated:
          containerID: containerd://9777e36af9c7bfbb86a8cead7206e0244eb99a7d76802fd41b6420a2e76564e7
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:27Z"
      name: kube-apiserver
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:03Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 192.168.1.2
    podIPs:
    - ip: 192.168.1.2
    qosClass: Burstable
    startTime: "2024-08-04T11:21:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 316c2d426555f181360ddbc49b9952c7
      kubernetes.io/config.mirror: 316c2d426555f181360ddbc49b9952c7
      kubernetes.io/config.seen: "2024-07-26T16:10:07.368115729Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-07-26T16:10:07Z"
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-control
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: control
      uid: 911a21c3-1fff-41f1-82b9-2396928106e8
    resourceVersion: "51380"
    uid: 499e899f-beff-4256-a6a1-64d6a3d0832b
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --allocate-node-cidrs=true
      - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --bind-address=127.0.0.1
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --cluster-cidr=10.244.0.0/16
      - --cluster-name=kubernetes
      - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      - --controllers=*,bootstrapsigner,tokencleaner
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      - --leader-elect=true
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --root-ca-file=/etc/kubernetes/pki/ca.crt
      - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --use-service-account-credentials=true
      image: registry.k8s.io/kube-controller-manager:v1.28.12
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/pki
        name: etc-pki
        readOnly: true
      - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        name: flexvolume-dir
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: control
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/pki
        type: DirectoryOrCreate
      name: etc-pki
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        type: DirectoryOrCreate
      name: flexvolume-dir
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:01Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:14Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:14Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://4463eccd463a6e5edf286cebff8c4f771afe2d49890a75e94a424dc644b51a71
      image: registry.k8s.io/kube-controller-manager:v1.28.12
      imageID: registry.k8s.io/kube-controller-manager@sha256:996c6259e4405ab79083fbb52bcf53003691a50b579862bf29b3abaa468460db
      lastState:
        terminated:
          containerID: containerd://a84dc6e08cd87c39208d44768188a2d8e33ba17a3f99865a6cb4c401b938bd7b
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:27Z"
      name: kube-controller-manager
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:03Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 192.168.1.2
    podIPs:
    - ip: 192.168.1.2
    qosClass: Burstable
    startTime: "2024-08-04T11:21:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-07-26T16:55:36Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 5969f8f5bc
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-bvmr6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: 49b8c5d6-83f1-41d0-8674-97d6cb530ea3
    resourceVersion: "52048"
    uid: fff6b852-3f53-494e-9f8d-df3d81c0fc87
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - node1
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.28.12
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-n8dln
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: node1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-n8dln
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T17:40:54Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:25:25Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:25:25Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:55:36Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://d828393b73a8672cbbb4e4c274dceebe9e87aaa72bad94b2873715b0c788ddd2
      image: registry.k8s.io/kube-proxy:v1.28.12
      imageID: registry.k8s.io/kube-proxy@sha256:7dd7829fa889ac805a0b1047eba04599fa5006bdbcb5cb9c8d14e1dc8910488b
      lastState:
        terminated:
          containerID: containerd://63d74fd655531738b7edc3e4ef24fec9b0d93ed82407ead3ffb5271543343d1e
          exitCode: 255
          finishedAt: "2024-08-04T11:25:12Z"
          reason: Unknown
          startedAt: "2024-08-04T08:59:07Z"
      name: kube-proxy
      ready: true
      restartCount: 4
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:25:25Z"
    hostIP: 192.168.1.3
    phase: Running
    podIP: 192.168.1.3
    podIPs:
    - ip: 192.168.1.3
    qosClass: BestEffort
    startTime: "2024-07-26T17:40:54Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-07-26T16:10:18Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 5969f8f5bc
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-lwlpb
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: 49b8c5d6-83f1-41d0-8674-97d6cb530ea3
    resourceVersion: "51374"
    uid: 97624227-a423-4a8d-9522-97d74877ebf3
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - control
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.28.12
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fvpkv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: control
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-fvpkv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:10:18Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:10:18Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://9efb2c71593299fc978be0e4c609740669109152801616fbe8a689241d03ca5a
      image: registry.k8s.io/kube-proxy:v1.28.12
      imageID: registry.k8s.io/kube-proxy@sha256:7dd7829fa889ac805a0b1047eba04599fa5006bdbcb5cb9c8d14e1dc8910488b
      lastState:
        terminated:
          containerID: containerd://7172ebd677ac9925bdc69d6af6d9bdf193c83ad00bc1fea9889664e4208cf1ba
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:33Z"
      name: kube-proxy
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:10Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 192.168.1.2
    podIPs:
    - ip: 192.168.1.2
    qosClass: BestEffort
    startTime: "2024-07-26T16:10:18Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 1a6de559fdecf5ba45b913be01e33e54
      kubernetes.io/config.mirror: 1a6de559fdecf5ba45b913be01e33e54
      kubernetes.io/config.seen: "2024-07-26T16:10:07.368116564Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-07-26T16:10:07Z"
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-control
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: control
      uid: 911a21c3-1fff-41f1-82b9-2396928106e8
    resourceVersion: "51397"
    uid: aa653d7f-6dd1-4f01-a77d-beee8d894065
  spec:
    containers:
    - command:
      - kube-scheduler
      - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
      - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
      - --bind-address=127.0.0.1
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      - --leader-elect=true
      image: registry.k8s.io/kube-scheduler:v1.28.12
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: control
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:01Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://51c34404e41d81a26aa4e2395ac0f621d8207fe87e65f2abb22575c849c385ac
      image: registry.k8s.io/kube-scheduler:v1.28.12
      imageID: registry.k8s.io/kube-scheduler@sha256:d93a3b5961248820beb5ec6dfb0320d12c0dba82fc48693d20d345754883551c
      lastState:
        terminated:
          containerID: containerd://b3f5e1d0749dacacd9588f3235f27a2415d3628383d08bfdd85e4dda4a6cbe34
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:27Z"
      name: kube-scheduler
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:03Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 192.168.1.2
    podIPs:
    - ip: 192.168.1.2
    qosClass: Burstable
    startTime: "2024-08-04T11:21:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-07-26T16:48:19Z"
    generateName: tigera-operator-76c4974c85-
    labels:
      k8s-app: tigera-operator
      name: tigera-operator
      pod-template-hash: 76c4974c85
    name: tigera-operator-76c4974c85-gczx6
    namespace: tigera-operator
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: tigera-operator-76c4974c85
      uid: 86fcebb1-725d-4ccf-88fb-5dcdeb6d71b2
    resourceVersion: "51372"
    uid: 9edb8a4b-d877-464e-b747-325b60de5979
  spec:
    containers:
    - command:
      - operator
      env:
      - name: WATCH_NAMESPACE
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: OPERATOR_NAME
        value: tigera-operator
      - name: TIGERA_OPERATOR_INIT_IMAGE_VERSION
        value: v1.34.0
      envFrom:
      - configMapRef:
          name: kubernetes-services-endpoint
          optional: true
      image: quay.io/tigera/operator:v1.34.0
      imagePullPolicy: IfNotPresent
      name: tigera-operator
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/calico
        name: var-lib-calico
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-7glrt
        readOnly: true
    dnsPolicy: ClusterFirstWithHostNet
    enableServiceLinks: true
    hostNetwork: true
    nodeName: control
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: tigera-operator
    serviceAccountName: tigera-operator
    terminationGracePeriodSeconds: 60
    tolerations:
    - effect: NoExecute
      operator: Exists
    - effect: NoSchedule
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/calico
        type: ""
      name: var-lib-calico
    - name: kube-api-access-7glrt
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:48:19Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-04T11:21:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-26T16:48:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://f6ebc75d52d2715dc0f6e21e811b9e37fa13f33653a0c7f3e919937a30bb2ebc
      image: quay.io/tigera/operator:v1.34.0
      imageID: quay.io/tigera/operator@sha256:479ddc7ff9ab095058b96f6710bbf070abada86332e267d6e5dcc1df36ba2cc5
      lastState:
        terminated:
          containerID: containerd://47416e68484221293a51a63cd6fc9055fef4bd2b56897fe5246c4531cd57914d
          exitCode: 255
          finishedAt: "2024-08-04T11:20:51Z"
          reason: Unknown
          startedAt: "2024-08-04T08:58:33Z"
      name: tigera-operator
      ready: true
      restartCount: 5
      started: true
      state:
        running:
          startedAt: "2024-08-04T11:21:10Z"
    hostIP: 192.168.1.2
    phase: Running
    podIP: 192.168.1.2
    podIPs:
    - ip: 192.168.1.2
    qosClass: BestEffort
    startTime: "2024-07-26T16:48:19Z"
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-07-26T16:55:00Z"
    labels:
      k8s-app: tigera-api
    name: calico-api
    namespace: calico-apiserver
    ownerReferences:
    - apiVersion: operator.tigera.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: APIServer
      name: default
      uid: c8520cb6-409a-4ff5-b5c7-767fcfd65f08
    resourceVersion: "4359"
    uid: fc9aafa7-cadd-435e-ae41-3b1ba250a649
  spec:
    clusterIP: 10.97.253.211
    clusterIPs:
    - 10.97.253.211
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: apiserver
      port: 443
      protocol: TCP
      targetPort: 5443
    selector:
      apiserver: "true"
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/port: "9094"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-07-26T16:54:56Z"
    labels:
      k8s-app: calico-kube-controllers
    name: calico-kube-controllers-metrics
    namespace: calico-system
    ownerReferences:
    - apiVersion: operator.tigera.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: Installation
      name: default
      uid: de04832b-a691-45fc-9ae4-0369dfe39d9f
    resourceVersion: "4316"
    uid: 721df9ad-455b-4d50-917b-a6a06a56b426
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: metrics-port
      port: 9094
      protocol: TCP
      targetPort: 9094
    selector:
      k8s-app: calico-kube-controllers
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-07-26T16:53:16Z"
    labels:
      k8s-app: calico-typha
    name: calico-typha
    namespace: calico-system
    ownerReferences:
    - apiVersion: operator.tigera.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: Installation
      name: default
      uid: de04832b-a691-45fc-9ae4-0369dfe39d9f
    resourceVersion: "3916"
    uid: 913dec65-6e5b-427a-bbc5-b3c0f903887e
  spec:
    clusterIP: 10.106.6.247
    clusterIPs:
    - 10.106.6.247
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: calico-typha
      port: 5473
      protocol: TCP
      targetPort: calico-typha
    selector:
      k8s-app: calico-typha
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-07-26T16:10:04Z"
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "193"
    uid: b090c1b4-5892-4a7f-ab56-179589279b4f
  spec:
    clusterIP: 10.96.0.1
    clusterIPs:
    - 10.96.0.1
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 6443
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/port: "9153"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-07-26T16:10:07Z"
    labels:
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: CoreDNS
    name: kube-dns
    namespace: kube-system
    resourceVersion: "261"
    uid: b90b6642-b0f7-45b9-9f62-cbb3b880ced8
  spec:
    clusterIP: 10.96.0.10
    clusterIPs:
    - 10.96.0.10
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: dns
      port: 53
      protocol: UDP
      targetPort: 53
    - name: dns-tcp
      port: 53
      protocol: TCP
      targetPort: 53
    - name: metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2024-07-26T16:53:17Z"
    generation: 1
    name: calico-node
    namespace: calico-system
    ownerReferences:
    - apiVersion: operator.tigera.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: Installation
      name: default
      uid: de04832b-a691-45fc-9ae4-0369dfe39d9f
    resourceVersion: "52124"
    uid: 0ed65a25-cfb1-41d6-b274-292bf1feccf5
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: calico-node
    template:
      metadata:
        annotations:
          hash.operator.tigera.io/cni-config: 0a4321e1231844b30534560ce90e56b5ba0a02a1
          hash.operator.tigera.io/system: fdde45054a8ae4f629960ce37570929502e59449
          tigera-operator.hash.operator.tigera.io/tigera-ca-private: 179b5319dd81d22ffffc77a3bb37ee203a051c1f
        creationTimestamp: null
        labels:
          app.kubernetes.io/name: calico-node
          k8s-app: calico-node
      spec:
        containers:
        - env:
          - name: DATASTORE_TYPE
            value: kubernetes
          - name: WAIT_FOR_DATASTORE
            value: "true"
          - name: CLUSTER_TYPE
            value: k8s,operator,bgp
          - name: CALICO_DISABLE_FILE_LOGGING
            value: "false"
          - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
            value: ACCEPT
          - name: FELIX_HEALTHENABLED
            value: "true"
          - name: FELIX_HEALTHPORT
            value: "9099"
          - name: NODENAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: FELIX_TYPHAK8SNAMESPACE
            value: calico-system
          - name: FELIX_TYPHAK8SSERVICENAME
            value: calico-typha
          - name: FELIX_TYPHACAFILE
            value: /etc/pki/tls/certs/tigera-ca-bundle.crt
          - name: FELIX_TYPHACERTFILE
            value: /node-certs/tls.crt
          - name: FELIX_TYPHAKEYFILE
            value: /node-certs/tls.key
          - name: FIPS_MODE_ENABLED
            value: "false"
          - name: NO_DEFAULT_POOLS
            value: "true"
          - name: FELIX_TYPHACN
            value: typha-server
          - name: CALICO_MANAGE_CNI
            value: "true"
          - name: CALICO_NETWORKING_BACKEND
            value: bird
          - name: IP
            value: autodetect
          - name: IP_AUTODETECTION_METHOD
            value: first-found
          - name: IP6
            value: none
          - name: FELIX_IPV6SUPPORT
            value: "false"
          - name: KUBERNETES_SERVICE_HOST
            value: 10.96.0.1
          - name: KUBERNETES_SERVICE_PORT
            value: "443"
          image: docker.io/calico/node:v3.28.0
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /bin/calico-node
                - -shutdown
          livenessProbe:
            failureThreshold: 3
            httpGet:
              host: localhost
              path: /liveness
              port: 9099
              scheme: HTTP
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 10
          name: calico-node
          readinessProbe:
            exec:
              command:
              - /bin/calico-node
              - -bird-ready
              - -felix-ready
            failureThreshold: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 10
          resources: {}
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              drop:
              - ALL
            privileged: true
            runAsGroup: 0
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/pki/tls/certs
            name: tigera-ca-bundle
            readOnly: true
          - mountPath: /etc/pki/tls/cert.pem
            name: tigera-ca-bundle
            readOnly: true
            subPath: ca-bundle.crt
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /var/run/nodeagent
            name: policysync
          - mountPath: /node-certs
            name: node-certs
            readOnly: true
          - mountPath: /var/run/calico
            name: var-run-calico
          - mountPath: /var/lib/calico
            name: var-lib-calico
          - mountPath: /var/log/calico/cni
            name: cni-log-dir
          - mountPath: /host/etc/cni/net.d
            name: cni-net-dir
        dnsPolicy: ClusterFirst
        hostNetwork: true
        initContainers:
        - image: docker.io/calico/pod2daemon-flexvol:v3.28.0
          imagePullPolicy: IfNotPresent
          name: flexvol-driver
          resources: {}
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              drop:
              - ALL
            privileged: true
            runAsGroup: 0
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /host/driver
            name: flexvol-driver-host
        - command:
          - /opt/cni/bin/install
          env:
          - name: CNI_CONF_NAME
            value: 10-calico.conflist
          - name: SLEEP
            value: "false"
          - name: CNI_NET_DIR
            value: /etc/cni/net.d
          - name: CNI_NETWORK_CONFIG
            valueFrom:
              configMapKeyRef:
                key: config
                name: cni-config
          - name: KUBERNETES_SERVICE_HOST
            value: 10.96.0.1
          - name: KUBERNETES_SERVICE_PORT
            value: "443"
          image: docker.io/calico/cni:v3.28.0
          imagePullPolicy: IfNotPresent
          name: install-cni
          resources: {}
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              drop:
              - ALL
            privileged: true
            runAsGroup: 0
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /host/opt/cni/bin
            name: cni-bin-dir
          - mountPath: /host/etc/cni/net.d
            name: cni-net-dir
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: calico-node
        serviceAccountName: calico-node
        terminationGracePeriodSeconds: 5
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists
        volumes:
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /var/run/nodeagent
            type: DirectoryOrCreate
          name: policysync
        - configMap:
            defaultMode: 420
            name: tigera-ca-bundle
          name: tigera-ca-bundle
        - name: node-certs
          secret:
            defaultMode: 420
            secretName: node-certs
        - hostPath:
            path: /var/run/calico
            type: ""
          name: var-run-calico
        - hostPath:
            path: /var/lib/calico
            type: ""
          name: var-lib-calico
        - hostPath:
            path: /opt/cni/bin
            type: ""
          name: cni-bin-dir
        - hostPath:
            path: /etc/cni/net.d
            type: ""
          name: cni-net-dir
        - hostPath:
            path: /var/log/calico/cni
            type: ""
          name: cni-log-dir
        - hostPath:
            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
            type: DirectoryOrCreate
          name: flexvol-driver-host
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 2
    desiredNumberScheduled: 2
    numberAvailable: 2
    numberMisscheduled: 0
    numberReady: 2
    observedGeneration: 1
    updatedNumberScheduled: 2
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2024-07-26T16:53:17Z"
    generation: 1
    name: csi-node-driver
    namespace: calico-system
    ownerReferences:
    - apiVersion: operator.tigera.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: Installation
      name: default
      uid: de04832b-a691-45fc-9ae4-0369dfe39d9f
    resourceVersion: "52122"
    uid: be9fa4a5-2644-4596-b3bf-7c8c3c5f4904
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: csi-node-driver
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/name: csi-node-driver
          k8s-app: csi-node-driver
          name: csi-node-driver
      spec:
        containers:
        - args:
          - --nodeid=$(KUBE_NODE_NAME)
          - --loglevel=$(LOG_LEVEL)
          env:
          - name: LOG_LEVEL
            value: warn
          - name: KUBE_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          image: docker.io/calico/csi:v3.28.0
          imagePullPolicy: IfNotPresent
          name: calico-csi
          resources: {}
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              drop:
              - ALL
            privileged: true
            runAsGroup: 0
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/run
            name: varrun
          - mountPath: /csi
            name: socket-dir
          - mountPath: /var/lib/kubelet
            mountPropagation: Bidirectional
            name: kubelet-dir
        - args:
          - --v=5
          - --csi-address=$(ADDRESS)
          - --kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)
          env:
          - name: ADDRESS
            value: /csi/csi.sock
          - name: DRIVER_REG_SOCK_PATH
            value: /var/lib/kubelet/plugins/csi.tigera.io/csi.sock
          - name: KUBE_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          image: docker.io/calico/node-driver-registrar:v3.28.0
          imagePullPolicy: IfNotPresent
          name: csi-node-driver-registrar
          resources: {}
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              drop:
              - ALL
            privileged: true
            runAsGroup: 0
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /csi
            name: socket-dir
          - mountPath: /registration
            name: registration-dir
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists
        volumes:
        - hostPath:
            path: /var/run
            type: ""
          name: varrun
        - hostPath:
            path: /var/lib/kubelet
            type: Directory
          name: kubelet-dir
        - hostPath:
            path: /var/lib/kubelet/plugins/csi.tigera.io
            type: DirectoryOrCreate
          name: socket-dir
        - hostPath:
            path: /var/lib/kubelet/plugins_registry
            type: Directory
          name: registration-dir
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 2
    desiredNumberScheduled: 2
    numberAvailable: 2
    numberMisscheduled: 0
    numberReady: 2
    observedGeneration: 1
    updatedNumberScheduled: 2
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2024-07-26T16:10:07Z"
    generation: 1
    labels:
      k8s-app: kube-proxy
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "52050"
    uid: 49b8c5d6-83f1-41d0-8674-97d6cb530ea3
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-proxy
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-proxy
      spec:
        containers:
        - command:
          - /usr/local/bin/kube-proxy
          - --config=/var/lib/kube-proxy/config.conf
          - --hostname-override=$(NODE_NAME)
          env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          image: registry.k8s.io/kube-proxy:v1.28.12
          imagePullPolicy: IfNotPresent
          name: kube-proxy
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/kube-proxy
            name: kube-proxy
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-proxy
        serviceAccountName: kube-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-proxy
          name: kube-proxy
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 2
    desiredNumberScheduled: 2
    numberAvailable: 2
    numberMisscheduled: 0
    numberReady: 2
    observedGeneration: 1
    updatedNumberScheduled: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-26T16:55:00Z"
    generation: 1
    labels:
      apiserver: "true"
      app.kubernetes.io/name: calico-apiserver
      k8s-app: calico-apiserver
    name: calico-apiserver
    namespace: calico-apiserver
    ownerReferences:
    - apiVersion: operator.tigera.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: APIServer
      name: default
      uid: c8520cb6-409a-4ff5-b5c7-767fcfd65f08
    resourceVersion: "51614"
    uid: f01e86d7-cc38-4019-9735-de0403a9802a
  spec:
    progressDeadlineSeconds: 600
    replicas: 2
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        apiserver: "true"
    strategy:
      type: Recreate
    template:
      metadata:
        annotations:
          tigera-operator.hash.operator.tigera.io/calico-apiserver-certs: c7b6ed2cab7b99882b4e7f931dfd81c8fae2280f
        creationTimestamp: null
        labels:
          apiserver: "true"
          app.kubernetes.io/name: calico-apiserver
          k8s-app: calico-apiserver
        name: calico-apiserver
        namespace: calico-apiserver
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    k8s-app: calico-apiserver
                namespaces:
                - calico-apiserver
                topologyKey: kubernetes.io/hostname
              weight: 100
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    k8s-app: calico-apiserver
                namespaces:
                - calico-apiserver
                topologyKey: topology.kubernetes.io/zone
              weight: 100
        containers:
        - args:
          - --secure-port=5443
          - --tls-private-key-file=/calico-apiserver-certs/tls.key
          - --tls-cert-file=/calico-apiserver-certs/tls.crt
          env:
          - name: DATASTORE_TYPE
            value: kubernetes
          - name: KUBERNETES_SERVICE_HOST
            value: 10.96.0.1
          - name: KUBERNETES_SERVICE_PORT
            value: "443"
          - name: MULTI_INTERFACE_MODE
            value: none
          image: docker.io/calico/apiserver:v3.28.0
          imagePullPolicy: IfNotPresent
          name: calico-apiserver
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 5443
              scheme: HTTPS
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            runAsGroup: 10001
            runAsNonRoot: true
            runAsUser: 10001
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /calico-apiserver-certs
            name: calico-apiserver-certs
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: calico-apiserver
        serviceAccountName: calico-apiserver
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - name: calico-apiserver-certs
          secret:
            defaultMode: 420
            secretName: calico-apiserver-certs
  status:
    availableReplicas: 2
    conditions:
    - lastTransitionTime: "2024-07-26T16:55:00Z"
      lastUpdateTime: "2024-07-26T16:55:18Z"
      message: ReplicaSet "calico-apiserver-7f5ddcdc69" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-08-04T11:22:04Z"
      lastUpdateTime: "2024-08-04T11:22:04Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 2
    replicas: 2
    updatedReplicas: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-26T16:53:17Z"
    generation: 1
    labels:
      app.kubernetes.io/name: calico-kube-controllers
      k8s-app: calico-kube-controllers
    name: calico-kube-controllers
    namespace: calico-system
    ownerReferences:
    - apiVersion: operator.tigera.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: Installation
      name: default
      uid: de04832b-a691-45fc-9ae4-0369dfe39d9f
    resourceVersion: "51525"
    uid: 99f20a95-58bc-4eb5-a4ac-184dd1642aa9
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: calico-kube-controllers
    strategy:
      type: Recreate
    template:
      metadata:
        annotations:
          hash.operator.tigera.io/system: fdde45054a8ae4f629960ce37570929502e59449
          tigera-operator.hash.operator.tigera.io/tigera-ca-private: 179b5319dd81d22ffffc77a3bb37ee203a051c1f
        creationTimestamp: null
        labels:
          app.kubernetes.io/name: calico-kube-controllers
          k8s-app: calico-kube-controllers
        name: calico-kube-controllers
        namespace: calico-system
      spec:
        containers:
        - env:
          - name: KUBE_CONTROLLERS_CONFIG_NAME
            value: default
          - name: DATASTORE_TYPE
            value: kubernetes
          - name: ENABLED_CONTROLLERS
            value: node
          - name: FIPS_MODE_ENABLED
            value: "false"
          - name: DISABLE_KUBE_CONTROLLERS_CONFIG_API
            value: "false"
          - name: KUBERNETES_SERVICE_HOST
            value: 10.96.0.1
          - name: KUBERNETES_SERVICE_PORT
            value: "443"
          - name: CA_CRT_PATH
            value: /etc/pki/tls/certs/tigera-ca-bundle.crt
          image: docker.io/calico/kube-controllers:v3.28.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - /usr/bin/check-status
              - -l
            failureThreshold: 6
            initialDelaySeconds: 10
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 10
          name: calico-kube-controllers
          readinessProbe:
            exec:
              command:
              - /usr/bin/check-status
              - -r
            failureThreshold: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 10
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 999
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/pki/tls/certs
            name: tigera-ca-bundle
            readOnly: true
          - mountPath: /etc/pki/tls/cert.pem
            name: tigera-ca-bundle
            readOnly: true
            subPath: ca-bundle.crt
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: calico-kube-controllers
        serviceAccountName: calico-kube-controllers
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: tigera-ca-bundle
          name: tigera-ca-bundle
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-26T16:53:17Z"
      lastUpdateTime: "2024-07-26T16:54:57Z"
      message: ReplicaSet "calico-kube-controllers-59488f4f55" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-08-04T11:21:47Z"
      lastUpdateTime: "2024-08-04T11:21:47Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-26T16:53:17Z"
    generation: 1
    labels:
      app.kubernetes.io/name: calico-typha
      k8s-app: calico-typha
    name: calico-typha
    namespace: calico-system
    ownerReferences:
    - apiVersion: operator.tigera.io/v1
      blockOwnerDeletion: true
      controller: true
      kind: Installation
      name: default
      uid: de04832b-a691-45fc-9ae4-0369dfe39d9f
    resourceVersion: "51630"
    uid: 11298d64-ba6c-4954-a897-ea829645ad96
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 2
    selector:
      matchLabels:
        k8s-app: calico-typha
    strategy:
      rollingUpdate:
        maxSurge: 100%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        annotations:
          hash.operator.tigera.io/system: fdde45054a8ae4f629960ce37570929502e59449
          tigera-operator.hash.operator.tigera.io/tigera-ca-private: 179b5319dd81d22ffffc77a3bb37ee203a051c1f
          tigera-operator.hash.operator.tigera.io/typha-certs: 8a8f7419ba03005d96764f9b47e43f85815e7fbc
        creationTimestamp: null
        labels:
          app.kubernetes.io/name: calico-typha
          k8s-app: calico-typha
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - calico-typha
                topologyKey: topology.kubernetes.io/zone
              weight: 1
        containers:
        - env:
          - name: TYPHA_LOGSEVERITYSCREEN
            value: info
          - name: TYPHA_LOGFILEPATH
            value: none
          - name: TYPHA_LOGSEVERITYSYS
            value: none
          - name: TYPHA_CONNECTIONREBALANCINGMODE
            value: kubernetes
          - name: TYPHA_DATASTORETYPE
            value: kubernetes
          - name: TYPHA_HEALTHENABLED
            value: "true"
          - name: TYPHA_HEALTHPORT
            value: "9098"
          - name: TYPHA_K8SNAMESPACE
            value: calico-system
          - name: TYPHA_CAFILE
            value: /etc/pki/tls/certs/tigera-ca-bundle.crt
          - name: TYPHA_SERVERCERTFILE
            value: /typha-certs/tls.crt
          - name: TYPHA_SERVERKEYFILE
            value: /typha-certs/tls.key
          - name: TYPHA_FIPSMODEENABLED
            value: "false"
          - name: TYPHA_SHUTDOWNTIMEOUTSECS
            value: "300"
          - name: TYPHA_CLIENTCN
            value: typha-client
          - name: KUBERNETES_SERVICE_HOST
            value: 10.96.0.1
          - name: KUBERNETES_SERVICE_PORT
            value: "443"
          image: docker.io/calico/typha:v3.28.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              host: localhost
              path: /liveness
              port: 9098
              scheme: HTTP
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 10
          name: calico-typha
          ports:
          - containerPort: 5473
            name: calico-typha
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              host: localhost
              path: /readiness
              port: 9098
              scheme: HTTP
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 10
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            runAsGroup: 10001
            runAsNonRoot: true
            runAsUser: 10001
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/pki/tls/certs
            name: tigera-ca-bundle
            readOnly: true
          - mountPath: /etc/pki/tls/cert.pem
            name: tigera-ca-bundle
            readOnly: true
            subPath: ca-bundle.crt
          - mountPath: /typha-certs
            name: typha-certs
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: calico-typha
        serviceAccountName: calico-typha
        terminationGracePeriodSeconds: 300
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: tigera-ca-bundle
          name: tigera-ca-bundle
        - name: typha-certs
          secret:
            defaultMode: 420
            secretName: typha-certs
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-26T16:53:17Z"
      lastUpdateTime: "2024-07-26T16:53:17Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-07-26T16:53:17Z"
      lastUpdateTime: "2024-07-26T16:53:30Z"
      message: ReplicaSet "calico-typha-776b6c4d8d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"nginx"},"name":"nginx-deployment","namespace":"default"},"spec":{"replicas":3,"revisionHistoryLimit":5,"selector":{"matchLabels":{"app":"temp-nginx"}},"strategy":{"type":"Recreate"},"template":{"metadata":{"labels":{"app":"temp-nginx"}},"spec":{"containers":[{"image":"nginx:1.14.2","name":"nginx","ports":[{"containerPort":80}]}]}}}}
    creationTimestamp: "2024-08-04T06:14:43Z"
    generation: 2
    labels:
      app: nginx
    name: nginx-deployment
    namespace: default
    resourceVersion: "51567"
    uid: 95f77640-9fc3-483b-bc70-b232a2b60849
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 5
    selector:
      matchLabels:
        app: temp-nginx
    strategy:
      type: Recreate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: temp-nginx
      spec:
        containers:
        - image: nginx:1.14.2
          imagePullPolicy: IfNotPresent
          name: nginx
          ports:
          - containerPort: 80
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-04T06:14:43Z"
      lastUpdateTime: "2024-08-04T06:15:09Z"
      message: ReplicaSet "nginx-deployment-54586f94c" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-08-04T11:21:56Z"
      lastUpdateTime: "2024-08-04T11:21:56Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-26T16:10:07Z"
    generation: 1
    labels:
      k8s-app: kube-dns
    name: coredns
    namespace: kube-system
    resourceVersion: "51518"
    uid: 6570bb81-a0d8-43e1-bd62-fa243c299c2f
  spec:
    progressDeadlineSeconds: 600
    replicas: 2
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.10.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 2
    conditions:
    - lastTransitionTime: "2024-07-26T16:54:41Z"
      lastUpdateTime: "2024-07-26T16:54:44Z"
      message: ReplicaSet "coredns-5dd5756b68" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-08-04T11:21:46Z"
      lastUpdateTime: "2024-08-04T11:21:46Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 2
    replicas: 2
    updatedReplicas: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-26T16:48:19Z"
    generation: 1
    labels:
      k8s-app: tigera-operator
    name: tigera-operator
    namespace: tigera-operator
    resourceVersion: "3375"
    uid: a3bb370a-1c13-4e1e-bd17-7399f8019c4c
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        name: tigera-operator
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: tigera-operator
          name: tigera-operator
      spec:
        containers:
        - command:
          - operator
          env:
          - name: WATCH_NAMESPACE
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OPERATOR_NAME
            value: tigera-operator
          - name: TIGERA_OPERATOR_INIT_IMAGE_VERSION
            value: v1.34.0
          envFrom:
          - configMapRef:
              name: kubernetes-services-endpoint
              optional: true
          image: quay.io/tigera/operator:v1.34.0
          imagePullPolicy: IfNotPresent
          name: tigera-operator
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/calico
            name: var-lib-calico
            readOnly: true
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: tigera-operator
        serviceAccountName: tigera-operator
        terminationGracePeriodSeconds: 60
        tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /var/lib/calico
            type: ""
          name: var-lib-calico
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-26T16:48:28Z"
      lastUpdateTime: "2024-07-26T16:48:28Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-07-26T16:48:19Z"
      lastUpdateTime: "2024-07-26T16:48:28Z"
      message: ReplicaSet "tigera-operator-76c4974c85" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-26T16:55:00Z"
    generation: 1
    labels:
      apiserver: "true"
      app.kubernetes.io/name: calico-apiserver
      k8s-app: calico-apiserver
      pod-template-hash: 7f5ddcdc69
    name: calico-apiserver-7f5ddcdc69
    namespace: calico-apiserver
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: calico-apiserver
      uid: f01e86d7-cc38-4019-9735-de0403a9802a
    resourceVersion: "51612"
    uid: 8fad5f60-e6c5-4676-bc76-e6cefd93f6cf
  spec:
    replicas: 2
    selector:
      matchLabels:
        apiserver: "true"
        pod-template-hash: 7f5ddcdc69
    template:
      metadata:
        annotations:
          tigera-operator.hash.operator.tigera.io/calico-apiserver-certs: c7b6ed2cab7b99882b4e7f931dfd81c8fae2280f
        creationTimestamp: null
        labels:
          apiserver: "true"
          app.kubernetes.io/name: calico-apiserver
          k8s-app: calico-apiserver
          pod-template-hash: 7f5ddcdc69
        name: calico-apiserver
        namespace: calico-apiserver
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    k8s-app: calico-apiserver
                namespaces:
                - calico-apiserver
                topologyKey: kubernetes.io/hostname
              weight: 100
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    k8s-app: calico-apiserver
                namespaces:
                - calico-apiserver
                topologyKey: topology.kubernetes.io/zone
              weight: 100
        containers:
        - args:
          - --secure-port=5443
          - --tls-private-key-file=/calico-apiserver-certs/tls.key
          - --tls-cert-file=/calico-apiserver-certs/tls.crt
          env:
          - name: DATASTORE_TYPE
            value: kubernetes
          - name: KUBERNETES_SERVICE_HOST
            value: 10.96.0.1
          - name: KUBERNETES_SERVICE_PORT
            value: "443"
          - name: MULTI_INTERFACE_MODE
            value: none
          image: docker.io/calico/apiserver:v3.28.0
          imagePullPolicy: IfNotPresent
          name: calico-apiserver
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 5443
              scheme: HTTPS
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            runAsGroup: 10001
            runAsNonRoot: true
            runAsUser: 10001
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /calico-apiserver-certs
            name: calico-apiserver-certs
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: calico-apiserver
        serviceAccountName: calico-apiserver
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - name: calico-apiserver-certs
          secret:
            defaultMode: 420
            secretName: calico-apiserver-certs
  status:
    availableReplicas: 2
    fullyLabeledReplicas: 2
    observedGeneration: 1
    readyReplicas: 2
    replicas: 2
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-26T16:53:17Z"
    generation: 1
    labels:
      app.kubernetes.io/name: calico-kube-controllers
      k8s-app: calico-kube-controllers
      pod-template-hash: 59488f4f55
    name: calico-kube-controllers-59488f4f55
    namespace: calico-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: calico-kube-controllers
      uid: 99f20a95-58bc-4eb5-a4ac-184dd1642aa9
    resourceVersion: "51522"
    uid: 61bf0885-d5b1-42eb-91dd-33055d10c58e
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: calico-kube-controllers
        pod-template-hash: 59488f4f55
    template:
      metadata:
        annotations:
          hash.operator.tigera.io/system: fdde45054a8ae4f629960ce37570929502e59449
          tigera-operator.hash.operator.tigera.io/tigera-ca-private: 179b5319dd81d22ffffc77a3bb37ee203a051c1f
        creationTimestamp: null
        labels:
          app.kubernetes.io/name: calico-kube-controllers
          k8s-app: calico-kube-controllers
          pod-template-hash: 59488f4f55
        name: calico-kube-controllers
        namespace: calico-system
      spec:
        containers:
        - env:
          - name: KUBE_CONTROLLERS_CONFIG_NAME
            value: default
          - name: DATASTORE_TYPE
            value: kubernetes
          - name: ENABLED_CONTROLLERS
            value: node
          - name: FIPS_MODE_ENABLED
            value: "false"
          - name: DISABLE_KUBE_CONTROLLERS_CONFIG_API
            value: "false"
          - name: KUBERNETES_SERVICE_HOST
            value: 10.96.0.1
          - name: KUBERNETES_SERVICE_PORT
            value: "443"
          - name: CA_CRT_PATH
            value: /etc/pki/tls/certs/tigera-ca-bundle.crt
          image: docker.io/calico/kube-controllers:v3.28.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - /usr/bin/check-status
              - -l
            failureThreshold: 6
            initialDelaySeconds: 10
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 10
          name: calico-kube-controllers
          readinessProbe:
            exec:
              command:
              - /usr/bin/check-status
              - -r
            failureThreshold: 3
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 10
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 999
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/pki/tls/certs
            name: tigera-ca-bundle
            readOnly: true
          - mountPath: /etc/pki/tls/cert.pem
            name: tigera-ca-bundle
            readOnly: true
            subPath: ca-bundle.crt
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: calico-kube-controllers
        serviceAccountName: calico-kube-controllers
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        - key: CriticalAddonsOnly
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: tigera-ca-bundle
          name: tigera-ca-bundle
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-26T16:53:17Z"
    generation: 1
    labels:
      app.kubernetes.io/name: calico-typha
      k8s-app: calico-typha
      pod-template-hash: 776b6c4d8d
    name: calico-typha-776b6c4d8d
    namespace: calico-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: calico-typha
      uid: 11298d64-ba6c-4954-a897-ea829645ad96
    resourceVersion: "51629"
    uid: 6071492b-e799-4636-9c31-554138947d66
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: calico-typha
        pod-template-hash: 776b6c4d8d
    template:
      metadata:
        annotations:
          hash.operator.tigera.io/system: fdde45054a8ae4f629960ce37570929502e59449
          tigera-operator.hash.operator.tigera.io/tigera-ca-private: 179b5319dd81d22ffffc77a3bb37ee203a051c1f
          tigera-operator.hash.operator.tigera.io/typha-certs: 8a8f7419ba03005d96764f9b47e43f85815e7fbc
        creationTimestamp: null
        labels:
          app.kubernetes.io/name: calico-typha
          k8s-app: calico-typha
          pod-template-hash: 776b6c4d8d
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - calico-typha
                topologyKey: topology.kubernetes.io/zone
              weight: 1
        containers:
        - env:
          - name: TYPHA_LOGSEVERITYSCREEN
            value: info
          - name: TYPHA_LOGFILEPATH
            value: none
          - name: TYPHA_LOGSEVERITYSYS
            value: none
          - name: TYPHA_CONNECTIONREBALANCINGMODE
            value: kubernetes
          - name: TYPHA_DATASTORETYPE
            value: kubernetes
          - name: TYPHA_HEALTHENABLED
            value: "true"
          - name: TYPHA_HEALTHPORT
            value: "9098"
          - name: TYPHA_K8SNAMESPACE
            value: calico-system
          - name: TYPHA_CAFILE
            value: /etc/pki/tls/certs/tigera-ca-bundle.crt
          - name: TYPHA_SERVERCERTFILE
            value: /typha-certs/tls.crt
          - name: TYPHA_SERVERKEYFILE
            value: /typha-certs/tls.key
          - name: TYPHA_FIPSMODEENABLED
            value: "false"
          - name: TYPHA_SHUTDOWNTIMEOUTSECS
            value: "300"
          - name: TYPHA_CLIENTCN
            value: typha-client
          - name: KUBERNETES_SERVICE_HOST
            value: 10.96.0.1
          - name: KUBERNETES_SERVICE_PORT
            value: "443"
          image: docker.io/calico/typha:v3.28.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              host: localhost
              path: /liveness
              port: 9098
              scheme: HTTP
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 10
          name: calico-typha
          ports:
          - containerPort: 5473
            name: calico-typha
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              host: localhost
              path: /readiness
              port: 9098
              scheme: HTTP
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 10
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            runAsGroup: 10001
            runAsNonRoot: true
            runAsUser: 10001
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/pki/tls/certs
            name: tigera-ca-bundle
            readOnly: true
          - mountPath: /etc/pki/tls/cert.pem
            name: tigera-ca-bundle
            readOnly: true
            subPath: ca-bundle.crt
          - mountPath: /typha-certs
            name: typha-certs
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: calico-typha
        serviceAccountName: calico-typha
        terminationGracePeriodSeconds: 300
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: tigera-ca-bundle
          name: tigera-ca-bundle
        - name: typha-certs
          secret:
            defaultMode: 420
            secretName: typha-certs
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-08-04T06:14:43Z"
    generation: 2
    labels:
      app: temp-nginx
      pod-template-hash: 54586f94c
    name: nginx-deployment-54586f94c
    namespace: default
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: nginx-deployment
      uid: 95f77640-9fc3-483b-bc70-b232a2b60849
    resourceVersion: "51566"
    uid: 2d26a8d9-01c3-4755-8167-414d28b87857
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: temp-nginx
        pod-template-hash: 54586f94c
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: temp-nginx
          pod-template-hash: 54586f94c
      spec:
        containers:
        - image: nginx:1.14.2
          imagePullPolicy: IfNotPresent
          name: nginx
          ports:
          - containerPort: 80
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-26T16:10:19Z"
    generation: 1
    labels:
      k8s-app: kube-dns
      pod-template-hash: 5dd5756b68
    name: coredns-5dd5756b68
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: coredns
      uid: 6570bb81-a0d8-43e1-bd62-fa243c299c2f
    resourceVersion: "51517"
    uid: 60a41ec5-76d4-462f-a9a8-ae1ef9ebba00
  spec:
    replicas: 2
    selector:
      matchLabels:
        k8s-app: kube-dns
        pod-template-hash: 5dd5756b68
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
          pod-template-hash: 5dd5756b68
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.10.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 2
    fullyLabeledReplicas: 2
    observedGeneration: 1
    readyReplicas: 2
    replicas: 2
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-26T16:48:19Z"
    generation: 1
    labels:
      k8s-app: tigera-operator
      name: tigera-operator
      pod-template-hash: 76c4974c85
    name: tigera-operator-76c4974c85
    namespace: tigera-operator
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: tigera-operator
      uid: a3bb370a-1c13-4e1e-bd17-7399f8019c4c
    resourceVersion: "3374"
    uid: 86fcebb1-725d-4ccf-88fb-5dcdeb6d71b2
  spec:
    replicas: 1
    selector:
      matchLabels:
        name: tigera-operator
        pod-template-hash: 76c4974c85
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: tigera-operator
          name: tigera-operator
          pod-template-hash: 76c4974c85
      spec:
        containers:
        - command:
          - operator
          env:
          - name: WATCH_NAMESPACE
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OPERATOR_NAME
            value: tigera-operator
          - name: TIGERA_OPERATOR_INIT_IMAGE_VERSION
            value: v1.34.0
          envFrom:
          - configMapRef:
              name: kubernetes-services-endpoint
              optional: true
          image: quay.io/tigera/operator:v1.34.0
          imagePullPolicy: IfNotPresent
          name: tigera-operator
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/calico
            name: var-lib-calico
            readOnly: true
        dnsPolicy: ClusterFirstWithHostNet
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: tigera-operator
        serviceAccountName: tigera-operator
        terminationGracePeriodSeconds: 60
        tolerations:
        - effect: NoExecute
          operator: Exists
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /var/lib/calico
            type: ""
          name: var-lib-calico
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
kind: List
metadata:
  resourceVersion: ""
